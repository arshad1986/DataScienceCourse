<header>
<h1>Core Concepts in Data Analysis</h1>
</header>
<div>
<h2>About the Course</h2>
<div>

This is an unconventional course in modern Data Analysis, Machine Learning and Data Mining. Its contents are heavily influenced by the idea that data analysis should help in enhancing and augmenting knowledge of the domain as represented by the concepts and statements of relation between them.

According to this view, two main pathways for data analysis are summarization, for developing and augmenting concepts, and correlation, for enhancing and establishing relations.

The term summarization embraces here both simple summaries like totals and means and more complex summaries: the principal components of a set of features and cluster structures in a set of entities. Similarly, correlation covers both bivariate and multivariate relations between input and target features including Bayes classifiers.

The view of the data as a subject of computational data analysis that is adhered to here has emerged quite recently. Typically, in sciences and in statistics, a problem comes first, and then the investigator turns to data that might be useful in advancing towards a solution.

Yet nowadays the situation is reversed frequently, especially with the advent of Big Data. Typical questions then are: Take a look at this data set – what sense can be made out of it? – Is there any structure in the data set? Can these features help in predicting those? This is more reminiscent to a traveler’s view of the world rather than that of a scientist. The scientist sits at his desk, gets reproducible signals from the universe and tries to accommodate them into a great model of the universe. The traveler deals with what come on their way – here is the data analysis niche.

A textbook by the instructor along these lines has been published by Springer-London in 2011: “Core concepts in data analysis is clean and devoid of any fuzziness. The author presents his theses with a refreshing clarity seldom seen in a text of this sophistication. …

To single out just one of the text’s many successes: I doubt readers will ever encounter again such a detailed and excellent treatment of correlation concepts. (Computing Reviews of ACM, June 2011).”<b></b><b></b>

<span style="font-size: 1.285714286rem; line-height: 1.6;">Course Syllabus</span>

</div>
<div>

<b>Week 1. Intro:</b> Examples of data<b> </b>and data analysis problems; visualization.

<b>Week 2. 1D analysis</b>. Feature scales. Histogram. Two common types of histograms: Gaussian and Power Law. Central values. Minkowski distance and data recovery view. Validation with Bootstrap.

<b>Week 3-4. 2D analysis</b> cases:

(Both quantitative: Scatter-plot, linear regression, correlation and determinacy coefficients: meaning and properties. Both nominal: Contingency table, Quetelet index, Pearson chi-squared coefficient, its double meaning and visualization).

<b>Week 5-6. Learning multivariate correlations</b>

(Bayes approach and Naïve Bayes classifier with a Bag-of-words text model; Decision trees and criteria for building them.)

<b>Week 7. Principal components (PCA) and SVD</b>

(SVD model behind PCA: student marks as the product of subject factor scores and subject loadings. Application to deriving a hidden underlying factor. Data visualization with PCA. Conventional PCA and data normalization issues.)

<b style="line-height: 1.714285714; font-size: 1rem;">Week 8. Clustering with k-means</b>

(K-Means iterations and K-Means features , K-Means criterion. Anomalous clusters and intelligent K-Means.)

</div>
<h2>Recommended Background</h2>
<div>
<ul>
	<li>Basics of calculus: the concepts of function, derivative and the first-order optimality condition;</li>
	<li>Basic linear algebra including vectors, inner products, Euclidean distances, matrices;</li>
	<li>Basic set theory notation; and</li>
	<li>Basic coding ability in an environment such as MatLab, or R, or any other software..</li>
</ul>
<span style="text-decoration: underline;"><strong>Links</strong></span>

</div>
</div>
<ul>
	<li><a href="http://eric.univ-lyon2.fr/~ricco/tanagra/fichiers/en_Tanagra_KMO_Bartlett.pdf">KMO and Bartlett test </a></li>
	<li><a href="http://factominer.free.fr/classical-methods">http://factominer.free.fr/classical-methods</a></li>
	<li>http://astrostatistics.psu.edu/su09/lecturenotes/pca.html</li>
</ul>
