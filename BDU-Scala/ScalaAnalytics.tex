
  
\chapter{Spark Overview for Scala Analytics}

(TS02V1EN) Version 1: January 2016

 

 \begin{quote}

The “Spark Overview for Scala Analytics” course will cover the history of Spark and how it came to be, how to build applications with Spark, establish an understanding of RDDs and DataFrames, and other advanced Spark topics. Apache Spark™ is a fast and general engine for large-scale data processing, with built-in modules for streaming, SQL, machine learning and graph processing. Having finished this class, a student would be prepared to leverage the core RDD and DataFrame APIs to perform analytics on datasets.
\end{quote}
This course is meant to be an overview of Spark and its associated ecosystem.  For deeper understanding of Spark, we recommend that students take the Spark Fundamentals courses I and II.
 

Welcome!
Page About this course PageNot completed
URL About your instructor URLNot completed
Technical assistance

%===========================================================================================%
\newpage

\section{Lesson 1 : Introduction to Spark}

\subsection{What is Spark}

After completing this lesson, you should be able to:

\begin{itemize}
\item Describe what Apache Spark is, and how it can be used to derive valuable information from data
\item Compare and contrast Spark to the Hadoop ecosystem
\item Discuss the various components of the Spark ecosystem
\end{itemize}

\subsection{Our first Spark Application}
After completing this lesson, you should be able to:

\begin{itemize}
\item Describe an RDD and its properties
\item Understand the basic workflow of a Word Count application with Spark
\end{itemize}

\subsection{The Spark Execution Model}

After completing this lesson, you should be able to:

\begin{itemize}
\item Describe the lineage of an RDD
\item Explain how stages of Spark jobs work
\item Discuss what shuffling of data means
\item The Spark Console
\end{itemize}
After completing this lesson, you should be able to:

Describe what the Spark Console is, and how it can be useful for understanding the runtime details of your Spark application

\subsection{Running Spark in a Standalone Cluster}

After completing this lesson, you should be able to:

\begin{itemize}
\item Describe Spark’s various deployment options
\item Discuss the role Resource Negotiators play in deciding what work is performed on which physical resources
\end{itemize}
Videos

Page What is Spark (6:13) Page Not completed; select to mark as complete
Page Our first Spark Application (4:55) Page Not completed; select to mark as complete
Page The Spark execution model (4:13) Page Not completed; select to mark as complete
Page The Spark Console (3:25) Page Not completed; select to mark as complete
Page Running Spark in a Standalone Cluster(3:12) Page Not completed; select to mark as complete

%======================================================================================%
\newpage
\section{Lesson 2 Introduction to RDDs}

\subsection{Tuning RDDs}

After completing this lesson, you should be able to:

The different kinds of methods available for RDDs
Partitioning, caching, and checkpointing, their importance and how to exploit them

\subsection{The Spark Web Console: A Deep Dive}

After completing this lesson, you should be able to:

How to interpret the various pages of the Spark Web Console
How to use the console to understand what your jobs are doing and how to improve their performance

\subsection{Broadcast Variables and Accumulators}

After completing this lesson, you should be able to:

How to send support data to tasks using broadcast variables.
How to accumulate information over all tasks for consumption back in the job’s driver.

\subsection{More Transformations: the Inverted Index Algorithm}

After completing this lesson, you should be able to:

More transformations available for building data applications
How to deconstruct data problems into sequences of transformation steps

\subsection{Refining the Inverted Index}

After completing this lesson, you should be able to:

Discuss how to sort data
Understand why to remove “stop words” using a Broadcast Variable
Explain how to identify which code runs in the driver and which code runs in the tasks across the cluster
Instructions

Review all the videos provided
Videos

Page Tuning RDDs(5:55) Page Not completed; select to mark as complete
Page Spark Web Console - A deep dive(4:30) Page Not completed; select to mark as complete
Page Broadcast Variables and Accumulators(3:51) Page Not completed; select to mark as complete
Page More Transformations: The inverted index Algorithm(7:00) Page Not completed; select to mark as complete
Page Refining the Inverted Index(6:12) Page Not completed; select to mark as complete


%======================================================================================%
\newpage
\section{Lesson 3: DataFrames for Large Scale Data Science}

\subsection{Introduction to SparkML}

After completing this lesson, you should be able to:

Describe what a DataFrame is
Outline the difference between RDDs and DataFrames, and why you might choose either one

\subsection{Exploring the DataFrame API}

After completing this lesson, you should be able to:

Leverage the DataFrame API to perform basic transformations
Describe the various ways DataFrames can be used
\subsection{DataFrame Data Sources I}

After completing this lesson, you should be able to:

Describe the various data sources supported by DataFrames
Discuss how to read and write JSON data with DataFrames
\subsection{DataFrame Data Sources II}

After completing this lesson, you should be able to:

Discuss how to add support for a new data source
Speeding Up with DataFrames

After completing this lesson, you should be able to:

Discuss how to create optimized data transformations using DataFrames
Describe how to limit the amount of data that is read in
Discuss basic optimization strategies
Instructions

Review all the videos provided
Videos

Page Introduction to SparkML(4:13) Page Not completed; select to mark as complete
Page Exploring the DataFrame API(5:55) Page Not completed; select to mark as complete
Page Dataframe Datasource I(3:41) Page Not completed; select to mark as complete
Page Dataframe Datasource II(3:35) Page Not completed; select to mark as complete
Page Speeding Up with DataFrames(4:21) Page Not completed; select to mark as complete


%======================================================================================%
\newpage
\section{Lesson 4 Advanced Spark Topics}

\subsection{DataFrame Joins}

After completing this lesson, you should be able to:

Describe the different kinds of joins supported by DataFrames
Explain how to write SQL queries
Discuss performance considerations

\subsection{Other DataFrame Transformations}

After completing this lesson, you should be able to:

Describe other available transformations, including:
agg
sample
randomSplit

\subsection{Using Hive with Spark SQL}

After completing this lesson, you should be able to:
\begin{itemize}
\item Describe how to create and drop Hive tables with Spark SQL
\item Discuss how to run Hive queries
\item Explain how to use the DataFrame API with query results
\end{itemize}

\subsection{Spark Streaming}
After completing this lesson, you should be able to:

Describe how Spark Streaming works
Explain the concept of DStreams, the core abstraction in Spark Streaming
Data Frames and Spark Streaming: Hive ETL

After completing this lesson, you should be able to:

Describe how to combine Spark Streaming and Hive to implement an ETL workflow
Videos

Page DataFrame Joins(4:47) Page Not completed; select to mark as complete
Page Other DataFrame Transformations(6:49) Page Not completed; select to mark as complete
Page Using Hive with Spark(7:26) Page Not completed; select to mark as complete
Page Spark Streaming(8:08) Page Not completed; select to mark as complete
Page DataFrames and Spark Streaming Hive(6:12) Page Not completed; select to mark as complete


%======================================================================================%
\newpage
\section{Lesson 5 Introduction to Spark MLlib}

\subsection{Spark with Scala}

After completing this lesson, you should be able to:
\begin{itemize}
\item Describe what machine learning is and how machines learn
\item Explain how Machine learning jobs are different than map-reduce jobs
\item Discuss the key components of Spark MLlib library
\end{itemize}
\subsection{Overview of Spark ML Algorithms}

After completing this lesson, you should be able to:
\begin{itemize}
\item Describe some of the algorithms that come with Spark MLlib
\item Explain the difference between supervised and unsupervised learning
\item Implement Alternating Least Squares and Kmeans algorithms
\end{itemize}

\subsection{Introduction to GraphX}

After completing this lesson, you should be able to:
\begin{itemize}
\item Describe the importance of graph processing
\item Discuss the GraphX library and its building blocks
\end{itemize}
%-----------------------------------------------%
\subsection{Sentiment Analysis of Twitter Stream I}

After completing this lesson, you should be able to:

\begin{itemize}
\itme Describe Naïve Bayes algorithm
\item Discuss how to build and train a machine learning algorithm from scratch
\end{itemize}
\subsection{Sentiment Analysis of Twitter stream II}

After completing this lesson, you should be able to:

Describe how to connect Spark streaming to Twitter
Explain steps required to integrate an ML algorithm to streaming
Videos

Page Introduction to SparkMLlib(3:36) Page Not completed; select to mark as complete
Page Overview of Spark ML Algorithms(9:12) Page Not completed; select to mark as complete
Page Introduction to GraphX(5:35) Page Not completed; select to mark as complete
Page Sentiment Analysis of Twitter Stream I(6:18) Page Not completed; select to mark as complete
Page Sentiment Analysis of Twitter Stream II(4:11) Page Not completed; select to mark as complete


%=============================================================================================%
\end{document}
