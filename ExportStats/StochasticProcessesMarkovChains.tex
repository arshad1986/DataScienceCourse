MS4217 Stochastic Processes - Markov Chains
%========================================================%
MS4217 Stochastic Processes - Markov Chains
Classification of States
Absorbing states
Classification of Chain
Irreducible Chain
Closed Sets
Ergodic Chains

%========================================================%








Classi cation of States
1. Absorbing state
2. Periodic state
3. Persistent state
4. Transient state
5. Ergodic state
%========================================================%
Absorbing states
Absorbing states are characterized in Markov chains by a value of 1 in the diagonal
element of the matrix (pii = 1). Once entered, there is no escaping the absorbing
states.
Classification of Chain
1. Irreducible sets
2. Closed sets
3. Ergodic chains
%========================================================%
Irreducible Chain
An irreducible chain is a chain in which every state is accessible from any other state
in a nite number of steps.
Closed Sets
A closed set is a subset of states that can not be escaped once entered. An absorbing
state is a closed set composed of one state.
%========================================================%


Once either states 3 or 4 are entered, it is not possible to
revert to states 1 or 2. States 3 and 4 will be the only states
visited.
%========================================================%
Ergodic Chains
For Ergodic Chains, the invariant distribution is the vector of
the mean recurrence time reciprocals.
%========================================================%
Sample Question
Consider a Markov chain with three states, 1, 2 and 3, and transition matrix 



Question 1: Explain what is meant by the statement that a Markov chain is an irreducible recurrent chain, and show, stating any general results that you assume, that this statement is true for the present chain.
 
Solution: A Markov chain is said to be irreducible if it is possible, with non-zero probability, to move from any state in the state space to any other state. A chain is said to be recurrent if, starting from any state in the space, the probability of eventually returning to that state is 1.

In the present case, because all the transition probabilities are non-zero, it is clearly possible to move from any state to any other state in one step, so the chain is irreducible. It is a general result that all finite irreducible Markov chains are recurrent

Question 2: Find the stationary distribution for this chain.

The stationary distribution (π1, π2, π3) is given by the solution of the equations

	

which reduce to

	

together with the normalisation condition 1+2+3= 1.
It readily follows that the solution is (1,2,3) = (0.25, 0.5 , 0.25).
