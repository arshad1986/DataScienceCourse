
\documentclass[a4paper,12pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{framed}
\usepackage{subfigure}
\usepackage{fancyhdr}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.00.0.2570}
%TCIDATA{<META NAME="SaveForMode"CONTENT="1">}
%TCIDATA{LastRevised=Wednesday, February 23, 201113:24:34}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{Language=American English}

\pagestyle{fancy}
\setmarginsrb{20mm}{0mm}{20mm}{25mm}{12mm}{11mm}{0mm}{11mm}
\lhead{MA4128} \rhead{Kevin O'Brien} \chead{Binary Classification} %\input{tcilatex}

%http://www.electronics.dit.ie/staff/ysemenova/Opto2/CO_IntroLab.pdf
\begin{document}

%------------------------------------------------------%
% http://www.psychwiki.com/wiki/Analyzing_Data
% http://www.upa.pdx.edu/IOA/newsom/semclass/ho_missing.pdf
% http://www.uvm.edu/~dhowell/StatPages/More_Stuff/Missing_Data/Missing.html
% http://www.uvm.edu/~dhowell/StatPages/More_Stuff/Missing_Data/Missing.html
% http://www.stat.columbia.edu/~gelman/arm/missing.pdf
% https://onlinecourses.science.psu.edu/stat505/node/78
% http://rer.sagepub.com/content/45/4/543.full.pdf
% http://www.kdnuggets.com/faq/precision-recall.html


%---------------------------------------------------------------------%
\section{Classification}
\subsection{What Is Classification}
classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known.
Discriminant analysis is an example of a \textbf{classification} method.

% It assumes that different classes generate data based on different Gaussian distributions.

\begin{itemize}
\item To train (create) a classifier, the fitting function estimates the parameters of a Gaussian distribution for each class.
\item To predict the classes of new data, the trained classifier finds the class with the smallest misclassification cost.
\end{itemize}
%-----------------------------------------------------------------------------------%
%\subsection{Recall and Precision}
%
%In a classification task, the precision for a class is the number of true positives (i.e. the number of items correctly labeled as belonging to the positive class) divided by the total number of elements labeled as belonging to the positive class (i.e. the sum of true positives and false positives, which are items incorrectly labeled as belonging to the class). Recall in this context is defined as the number of true positives divided by the total number of elements that actually belong to the positive class (i.e. the sum of true positives and false negatives, which are items which were not labeled as belonging to the positive class but should have been).



%-----------------------------------------------------------------------%
\subsection{Types I and II Error}
A type I error is the incorrect rejection of a true null hypothesis.
A type II error is the failure to reject a false null hypothesis.
A type I error is a false positive. Usually a type I error leads one to conclude that a thing
or relationship exists when really it doesn't.
A type II error is a false negative.
\begin{tabular}{|c|c|c|}
  \hline
  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...

& Null hypothesis ($H_0$) is true	& Null hypothesis ($H_0$) is false\\ \hline
Reject  & Type I error          & Correct outcome \\
null hypothesis 			& False positive	& True positive\\ \hline
Fail to reject 	&Correct outcome&Type II error\\
null hypothesis & True negative	& False negative\\
  \hline
\end{tabular}
%-----------------------------------------------------------------------%
\subsection{False Positive and False Negative error}

A false positive error, commonly called a ``false alarm" is a result that indicates a
given condition has been fulfilled, when it actually has not been fulfilled.
A false positive error is a \textbf{Type I error} where the test is checking a single condition,
and results in an affirmative or negative decision usually designated as "true or false".

A false negative error is where a test result indicates that a condition failed, while it actually was successful.
A false negative error is a \textbf{Type II error} occurring in test steps where a single
condition is checked for and the result can either be positive or negative.



%-------------------------------------------------------------------------------------%

\subsection{Sensitivity and Specificity}

Sensitivity and specificity are measures of the performance of a binary classification test.

\begin{itemize}
\item Sensitivity (also called the true positive rate, or the \textbf{recall} rate) measures the proportion of actual positives which are correctly identified as such (e.g. the percentage of sick people who are correctly identified as having the condition).
    \[ \mbox{sensitivity (Recall)} = \frac{ \mbox{number of true positives} } {\mbox{number of true positives} + \mbox{number of false negatives}} \]

\item Specificity measures the proportion of negatives which are correctly identified as such (e.g. the percentage of healthy people who are correctly identified as not having the condition, sometimes called the true negative rate).
    \[ \mbox{ Specificity} = \frac{ \mbox{number of true negatives} } {\mbox{number of false positives} + \mbox{number of true negatives}} \]

\end{itemize}

(Remark: We will use the terms \textbf{Sensitivity} and \textbf{Recall} interchangeably. Sensitivity is more commonly used in a medical context, while recall is more commonly used in data science.)

\end{document}
